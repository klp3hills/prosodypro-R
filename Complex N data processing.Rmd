---
title: "Complex N Data Processing"
author: "Kevin L. Penner"
date: "February 25, 2016"
output: html_document
---

***
# Introduction
***

This document describes the process of getting the Complex Noun production experiment (May 28-29, 2015) data (i.e. the ProsodyPro output) into R and begin processing, visualizing and doing analysis with it. Specifically, the script imports "ensemble" output files from the [ProsodyPro](http://www.homepages.ucl.ac.uk/~uclyyix/ProsodyPro/) Praat script developed by Yi Xu. These files are aggregate calculations for all tokens of each wordlist item for each speaker of various acoustic properties (e.g. f0, duration, intensity, etc). It is assumed that the ProsodyPro ensemble files have already been created as described in ***How to create ensemble files with ProsodyPro 6.1.4 beta***.


***
# Get the data into R
***

The first step is to get the data into R using the script `get_ensemble_files.R`. 

The script will...

1. Create a `list` of `dataframes` (`dataset.list`)--one `dataframe` for each type of "ensemble" file (e.g. mean_normf0, maxf0, minf0, etc.)
2. Get the list of speaker folders (directories) from the directory assigned to `sp.dir`
3. Get the list of `.txt` files in each speakers folder
4. Read in all the `.txt` files for a speaker and store in a temporary `dataframe` 

> New 2016-02-26: rows with unequal number of columns (data points) are correctly handled even if the first row has less than the max number of columns; missing values in short rows are assigned 'NA' at the END of the row

5. Append each type of file to the appropriate `dataframe` in the `list` (i.e. all mean\_f0 files get stored in the `list` item `dataset.list$mean_f0`, etc.)
6. Saves a file listing all the *ProsodyPro* files processed to the directory assigned to `sp.dir`

See *Using R to Get ProsodyPro Ensemble Output.Rmd* for a more in depth explanation of the script.

## Before running `get_ensemble_files.R` 

Because of the way I extract the gloss from the filename using a regular expression, it is easiest to change **Las_Trojes** to lowercase (**las_trojes**) and **ceñidor_para_mujer** to **ceñidor**. To do this, 

1. search for all the `.txt` files in the folder
2. drop the onto the **TextWrangler.app** icon
3. do a Multi-File Search & Replace


## Run the script `get_ensemble_files.R` 

Run the script `get_ensemble_files.R` with the path to the folder containing the folders for each speaker's data for the Complex N experiment assigned to the variable `sp.dir`. This script will create the list `dataset.list`, which has a separate list item for each type ensemble file (e.g. `duration`, `normf0`, `mean_normf0`, etc). Each list item has the all the data from ensemble file of that type for each speaker. So, the `duration` list item contains all the duration data from each speaker in the experiment stored in a dataframe.

You can explore any `dataframe` in this `list` by replacing `duration` with a different `dataframe` name in the following code:
```
names(dataset.list) # Find out the names of each dataframe in the list
head(dataset.list[['duration']]) # view the first 8 observations in the dataframe
tail(dataset.list[['duration']]) # view the last 8 observations in the dataframe
nrow(dataset.list[['duration']]) # view the number of observations in the dataframe
unique(dataset.list[['duration']]$sp) # view all speakers with data in the dataframe
```

## Taking care of missing data

> **Nothing to do here:** After working out the steps below I decided it was too much work, and probably wouldn't work anyway because the files with the token means wouldn't be correct. Instead I decided to **omit the tokens with TBUs that were completely devoiced/elided**. This requires that a **repetition list** (`repetition_list.txt`) be used when creating the **ProsodyPro** ensemble files (Task #3), and the ***Use repetition list*** box checked. To do this, use FileList.txt (automatically generated by ProsodyPro) which contains a list of all the sound file names in the speaker folder. Insert blank lines between list items and delete the names of files to exclude from analysis.


The `get_ensemble_files.R` script is able to fill NA into observation with empty data points (fewer than the maximum number of data culumns), but in some cases devoicing/elision resulted in a token that had fewer annotated intervals (recall that calculations are only made on annotated intervals by ProsodyPro) than other tokens of the same item. (These have been noted in the [experiment processing comments](https://www.evernote.com/shard/s66/nl/1915424551/b0754638-8b1c-4071-a2c8-40fa5a3ea7b0/) in Evernote.) In these cases, the data needs to be shifted over so that it lines up with the proper TBU (interval), and fill NA into the data samples that correspond to the TBU (interval) with the voiceless/elided segment. It is important to do this **before** doing the across item averaging, so that the proper values are averaged. For instance, items in the Complex N experiment which have three TBUs (e.g. chitoˀo 'dueño') will have  30 f0 (and other) samples  taken (10 for each TBU = labeled interval), but if the first TBU is missing due to devoicing/elision, then the f0 samples must be shifted to the right 10 columns, and the first 10 columns filled with NA. These will be skipped in the aggregate calculations and plotting.

Here are the steps to do this using MQM dueño_7, which devoiced/elided /i/ in /chitoˀo/:

1. In **Finder** open the folder with the speakers data for the experiment, type ⌘F and search for all the data with the gloss for the item with missing data, e.g. `name:dueño_7` 
  + click the folder name in the in the bar after "Search:" so it only searches in that folder
2. Open the file `H_dueño_7.normtimef0` in **TextWrangler.app**
  + Open **TextWrangler.app** then drag the file onto the icon
  + Observe that there are missing data related to the devoiced/elided interval
    - In this file, there are 10 observations for the interval labled *o* and 10 for the interval labled *ˀo*, but none for the initial TBU which would have been labeled *i* if it wasn't elided
  + Open a file without missing data to see what it should look like
3. Fill in the `rowLabel`, `NormalizedTime` (10 consecutive integers) and `Tab + NA` for `F0` for the 10 missing observations for each elided TBU
  + This can either be done in **TextWrangler.app** or copy & paste it into a **LibreOffice.app** spreadsheet
    - Make sure to save as .csv with tab delimiters
4. Adjust the interger values for `NormalizedTime` for the other tokens to be sequential with the inserted ones
5. Follow the steps to change these files:
  + `H_dueño_7.actutimenormf0`
  + `H_dueño_7.f0velocity`
  + `H_dueño_7.normtime_f0velocity`
  + `H_dueño_7.normtime_semitonef0`
  + `H_dueño_7.normtimef0`
  + `H_dueño_7.normtimeIntensity`
  + `H_dueño_7.samplef0`
  + `H_dueño_7.semitonef0`
  + `H_dueño_7.smoothf0`
    

***
# Plotting the `mean_normf0` data
***

The data in the `mean_normf0` dataframe contains the average of the time normalized f0 data for each token of each wordlist item for each speaker. That is, there were 38 items in the Complex N experiment, and each was repeated 8 times by each of 4 speakers. The time normalized f0 data from each of the 8 repetitions of each item by a speaker was converted into semitones, averaged, converted back to Hertz, and stored in the `mean_normf0.txt` file and imported into this `dataframe`. Thus, there is only one observation (record) per wordlist item per speaker in this `dataframe`.

There are a number of scripts for plotting the Complex N data mean_normf0 data, which are listed below. Only those marked ***Implemented*** have been finished. **Before using these plotting scripts, go through the next two sections on exploring and adding variables to the dataset.**

* Plot a **single wordlist item** from a **single speaker** to the **screen** -- ***Implemented***
    + `Plot_ComplexN_single.R`
* Plot **all wordlist items** from a ***single speaker*** to a **PDF** -- ***Implemented***
    + `Plot_ComplexN_single.R`
* Make a single plot (overlayed) of **several wordlist items** from a single speaker -- ***Implemented***
    + `Plot_multi_ComplexN_single_speaker.R`
* Plot the **average** of **single wordlist item** for **all speakers** to the **screen**
* Plot the **average** of **all wordlist items** for **all speakers** to a **PDF**
* Make a single plot (overlayed) of the **average** of **several wordlist items** for **all speakers** to a **PDF**
* Etc.

## Explore the `mean_normf0` dataset and copying it to ```dat```

Extract the `mean_normf0` data to `dat` for safer and easier processing:
```
dataset.list[['mean_normf0']] -> dat
```

Explore `dat`:
```
str(dat)
```

Look at the first 8 observations:
```
head(dat)
tail(dat)
```

Find the different speakers:
```
unique(dat$sp)
```

## Add extra variables to the `mean_normf0` dataset

### Add a variable for the noun of each item (```dat$noun```)

noun <- gsub("_[HL_]*(.+)_","\\1", dat$X1)
dat$noun <- noun # add this to the dataframe
table(dat$noun) # inspect

> This is the old way:

```
noun <- vector(length=0)
for (i in 1:nrow(dat)) {
  # extract the noun from the filename in the first column by skipping the 1st (_, _H_, or _L_) & last character (="_")
  noun <- c(noun,substr(dat[i,1],2,nchar(dat[i,1])-1)) # this is the old way
}
dat$noun <- noun # add this to the dataframe
table(dat$noun) # inspect
```

### Add variables for the Mixtec word, tone melody and IPA of each item

#### Read in list of nouns with melodies

The list of noun melodies must already exist as a tab separated csv file. The one I created for the Complex N data is ```/Users/Kevin/Fieldwork-vmj/_exp_data/ComplexN/ComplexNMixtecToneList.csv```. It has the following variables (column names) in this order: 
```mix``` -- item in Mixtec orthography,
```mel``` -- tonal melody,
```ipa``` -- item in IPA,
```g``` -- English gloss,
```cv``` -- consonant/vowel (CV) structure.

```
melody.list <- read.table(file.choose(), header=T, sep="\t", encoding="UTF-8")
melody.list
str(melody.list)
head(melody.list)
tail(melody.list)
```

#### Convert `mix`, `mel` and `ipa` variables from factors to character strings

```
for (i in 1:ncol(melody.list)) {
  melody.list[,i] <- as.character(melody.list[,i])
}
```

#### Copy ```dat$noun``` to new variables ```dat$mix```, ```dat$mel``` & ```dat$ipa```

```
dat$mix <- dat$noun
dat$mel <- dat$noun
dat$ipa <- dat$noun
dat$cv <- dat$noun
```

#### Substitue the proper Mixtec word, melody and ipa from ```melody.list``` for each noun in ```dat$mix```, ```dat$mel``` and ```dat$ipa```

> SKIP THIS! I replaced the missing data for MQM so this step should NOT be done.

In order for this to work, there must be an observation (row) for each of the wordlist items. If an item is missing, delete that item from melody.list, or the script won't work. Initially, when processing just MQM data, there was no data for 'ceñidor', so I had to delete this from `melody.list`, so I stored the original wordlist data in `melody.list.original`:

```
melody.list -> melody.list.original # save the original list
head(melody.list) # check which item belongs to 'ceñidor para mujer'
melody.list <- melody.list[-2,] # delete that item
```

> RESUME HERE:

Later, however, I added this data, so I could use the full list.

Once you have the correct list, execute this code to substitue the proper Mixtec word, melody and ipa from ```melody.list``` for each noun in ```dat$mix```, ```dat$mel``` and ```dat$ipa```:

```
for (i in 1:nrow(melody.list)) { 
  dat[dat$mix==melody.list[i,]$g,]$mix <- melody.list[i,]$mix
  dat[dat$mel==melody.list[i,]$g,]$mel <- melody.list[i,]$mel
  dat[dat$ipa==melody.list[i,]$g,]$ipa <- melody.list[i,]$ipa
  dat[dat$cv==melody.list[i,]$g,]$cv <- melody.list[i,]$cv
}
```

#### Check the Mixtec, melodies & IPA are correct

```
names(dat)
dat[,c(1,43:47)] # list the new data with the filename (1st column) for comparison
```


## Plotting

Choose from the plotting options below that indicate that they have been ***Implemented*** and run the script indicated for that particular option:

* Plot a **single wordlist item** from a **single speaker** to the **screen** -- ***Implemented***
    + `Plot_ComplexN_single.R`
* Plot **all wordlist items** from a **single speaker** to a **PDF** -- ***Implemented***
    + `Plot_ComplexN_single.R`
* Make a single plot (overlayed) with **several wordlist items** from a **single speaker** -- ***Implemented*** 
    + `Plot_multi_ComplexN_single_speaker.R`
* Plot the **average** of **single wordlist item** for all speakers to the screen
* Plot the **average** of **all wordlist items** for all speakers to a PDF
* Make a single plot (overlayed) of the **average** of **several wordlist items** for all speakers to a PDF
* Etc.


***
# Plotting `normf0` data
***

## Exploring the `normf0` dataset

Extract the `normf0` data to `dat` for easier processing:
```
dataset.list[['normf0']] -> dat
```

Explore `dat`:
```
str(dat)
```

Look at the first 8 observations:
```
head(dat)
```

Find the different speakers:
```
unique(dat$sp)
```

## Adding extra variables to the `normf0` dataset

### Adding the wordlist item as a variable

Extract the wordlist item from the Normtime variable (which contains the filename), stripping off the leading "_" and trailing "_" and digit:

```
item <- substr(dat$Normtime, 2, nchar(dat$Normtime)-2)
table(item)
dat$item <- item
```

### Adding the repetition number

Extract the repetition number for each observation from the Normtime variable (the final digit in Normtime):
```
num <- substr(dat$Normtime, nchar(dat$Normtime), nchar(dat$Normtime))
table(num)
dat$num <- num
```

